from sklearn.naive_bayes import MultinomialNB
from Preprocessing import *
from Readfile import *
from TFIDF import *
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
from Evaluate import *
# label, id_list, indexxuoc, indexid, df, data = readfile()
# new_review, uni_new_review= Preprocessing(data)
# new_review = new_review + uni_new_review
# label = label + label

def Naive(data, label):
    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.33, random_state=42)
    clf = MultinomialNB()
    print(X_train.shape)
    scores = cross_val_score(clf, X_train, y_train, cv = 5)
    print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
# y_pred = clf.predict(X_test)
# print(classification_report(y_test, y_pred))
    print('done dataload')
    start = time.time()
    print(datetime.datetime.utcnow())
    # scores = cross_val_score(clf, X_train, y_train, cv = 5)
    # print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
    print('begin training')
    clf.fit(X_train, y_train)
    end = time.time()
    print(end - start)
    print(datetime.datetime.utcnow())
    model = 'Model/NaiveB.sav'
    pickle.dump(clf, open(model, 'wb'))
    print('save model done')

    y_pred = clf.predict(X_test)
    result = accuracy_score(y_test, y_pred)
    print("Accuracy - test set: %.2f%%" % (result * 100.0))
    print(classification_report(y_test, y_pred))
    print(type(y_pred))
    print(type(y_test))
    Evaluate_Model(y_pred.tolist(), y_test)

# vectordata = Tfidf(new_review)
# Naive(vectordata,label)

data_new = ["T·ªá. Gi√†y s·ª©t ch·ªâ h·ªôp r√°ch. Th·ªùi gian giao h√†ng r·∫•t ch·∫≠m",
            "Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m !!!To√†n b·ªã s·ªùn ch·ªâ !!! Kh√¥ng ƒë√∫ng v·ªõi m√¥ t·∫£ c·ªßa s·∫£n ph·∫©m !!!",
            "H√†ng l·ªói. S·∫°c h·ªèng. Lm ƒÉn qu√° ch√°n R·∫•t kh√¥ng ƒë√°ng ti·ªÅn R·∫•t kh√¥ng ƒë√°ng ti·ªÅn",
            "S·∫£n ph·∫©m g·ªôi r·∫•t l√† c·ª©ng t√≥c.m√πi th∆°m nh∆∞ ki·ªÉu ho√° ch·∫•t. Ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m r·∫•t k√©m.",
            "c·ª±c kh√¥ng ·ªïn üôÅüôÅüôÅ, ch·∫•t l∆∞·ª£ng k√©m",
            "kh√¥ng t·ªët nh∆∞ k·ª≥ v·ªçng",
            'h√†ng d·ªüm',
            'h√†ng kh√¥ng t·ªët',
            "K√©m ch·∫•t l∆∞·ª£ng",
            'H√†ng t·ªët. ƒê√≥ng g√≥i sp k·ªπ. Nh√¢n vi√™n t∆∞ v·∫•n n√™n c√≥ th√°i ƒë·ªô d·ªÖ ch·ªãu h∆°n',
            "·ªïn",
            "r·∫•t ·ªïn",
            "ch·∫•t l∆∞·ª£ng k√©m, pin h·∫øt nhanh",
            "·ªêp n√†o c≈©ng ƒë·∫πp h·∫øt th√≠ch c·ª±c lu√¥nnnnn",
            "H√†ng r·∫•t t·ªët",
            "b·ª±c m√¨nh, ch√°n",
            "Shop ph·ª•c v·ª• qu√° t·ªá. Mua pho mai s·ª£i m√† b√°n pho mai l√°t. L√°t pho mai c√≥ m√πi v√† m√≥p m√©o",
            "ƒê√£ nh·∫≠n ƒëc 1 c√°i. Thanks shop ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m tuy·ªát v·ªùi ƒê√≥ng g√≥i s·∫£n ph·∫©m r·∫•t ƒë·∫πp v√† ch·∫Øc ch·∫Øn Shop ph·ª•c v·ª• r·∫•t t·ªët",
            "S·∫£n ph·∫©m kh√¥ng bi·∫øt c√≥ t·ªët hay kh√¥ng ?v√¨ mu·ªën ƒë√°nh gi√° ph·∫£i c√≥ th·ªùi gian ki·ªÉm tra  ƒë√£ ki·ªÉm tra ch·∫•t l∆∞·ª£ng nh∆∞ con cac",
            "H√†ng nh√°i ·ªçp √† ·ªçp ·∫πp",
            "L·∫•y size t·ª´ 12/14 kg m√† m·∫∑c ko v·ª´a .ch√¢t l∆∞·ª£ng th√¨ ok nh∆∞ng m·∫∑c ch·∫≠t", #1
            "∆∞ng c·ª±c k·ª≥.",
            "H√†ng qu√° ch√°n m·∫•y b·ªô b√© zai kh√°c v·ªõi h√¨nh shop ƒëƒÉng b√°n kh√¥ng  c√≥ b·ªô n√†o m√¨nh ch·ªçn gi·ªëng nh∆∞ l√∫c ƒë·∫∑t"]
# data_label = np.array([1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,1,    1,1,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,0,1,1,1,0,1])
# data, unidata = Preprocessing(data_new)
# data = data + unidata
def Naive_TFidf(data):

    tfidf_model = pickle.load(open("C://Users//locco//PycharmProjects//SentimentAnalysis//Model//tfidf.pickle", "rb"))
    vector = tfidf_model.transform(data)
    vectordata = vector.todense()
    clf = pickle.load(open("C://Users//locco//PycharmProjects//SentimentAnalysis//Model//NaiveB.sav", "rb"))
    result = clf.predict(vectordata)
    return result

# result = Naive_TFidf(data)
# print(result)
#
# for i in range(0, len(result)):
#     if (result[i] != data_label[i]):
#         print(i)
#         print(data[i])
#         print(result[i])
# Evaluate_Model(result, data_label)